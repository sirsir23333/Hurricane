{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import json\n",
    "import kml2geojson as k2g\n",
    "import zipfile\n",
    "import requests\n",
    "import shutil\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "import xml.etree.ElementTree as ET\n",
    "from lxml import etree\n",
    "from datetime import datetime\n",
    "import subprocess\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMZ File URL 1: https://www.metoc.navy.mil/jtwc/products/wp2124.kmz\n",
      "KMZ file 1 saved to C:\\Users\\CrudeIntern\\OneDrive - Hengli Petrochemical International Pte Ltd\\Market Analysis\\Current Projects\\Hurricane\\wp2124.kmz\n",
      "KMZ File URL 2: https://www.metoc.navy.mil/jtwc/products/ep9924.kmz\n",
      "KMZ file 2 saved to C:\\Users\\CrudeIntern\\OneDrive - Hengli Petrochemical International Pte Ltd\\Market Analysis\\Current Projects\\Hurricane\\ep9924.kmz\n",
      "['C:\\\\Users\\\\CrudeIntern\\\\OneDrive - Hengli Petrochemical International Pte Ltd\\\\Market Analysis\\\\Current Projects\\\\Hurricane\\\\wp2124.kmz', 'C:\\\\Users\\\\CrudeIntern\\\\OneDrive - Hengli Petrochemical International Pte Ltd\\\\Market Analysis\\\\Current Projects\\\\Hurricane\\\\ep9924.kmz']\n",
      "['wp2124', 'ep9924']\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "base_directory = r\"C:\\Users\\CrudeIntern\\OneDrive - Hengli Petrochemical International Pte Ltd\\Market Analysis\\Current Projects\\Hurricane\"\n",
    "def webscraping_kmz(base_directory: str) -> None:\n",
    "    driver = webdriver.Chrome()\n",
    "    try:\n",
    "        url = \"https://www.metoc.navy.mil/jtwc/jtwc.html\"\n",
    "        driver.get(url)\n",
    "        driver.implicitly_wait(5)\n",
    "        kmz_link_elements = WebDriverWait(driver, 5).until(\n",
    "            EC.presence_of_all_elements_located((By.LINK_TEXT, \"Google Earth Overlay\"))\n",
    "        )\n",
    "        if not kmz_link_elements:\n",
    "            print(\"No Google Earth Overlay links found.\")\n",
    "            return\n",
    "        file_names, kmz_file_paths = [], []\n",
    "        for index, kmz_link_element in enumerate(kmz_link_elements):\n",
    "            kmz_url = kmz_link_element.get_attribute('href')\n",
    "            print(f\"KMZ File URL {index + 1}: {kmz_url}\")\n",
    "            file_name = kmz_url.split('/')[-1].split('.')[0]\n",
    "            kmz_file = requests.get(kmz_url) \n",
    "            kmz_file_path = os.path.join(base_directory, f'{file_name}.kmz')\n",
    "            kmz_file_paths.append(kmz_file_path)\n",
    "            file_names.append(file_name)\n",
    "            with open(kmz_file_path, 'wb') as f:\n",
    "                f.write(kmz_file.content)\n",
    "            print(f\"KMZ file {index + 1} saved to {kmz_file_path}\")\n",
    "    except Exception as e:\n",
    "        print(\"Error occurred while scraping KMZ files:\", e)\n",
    "    finally:\n",
    "        driver.quit()\n",
    "    return kmz_file_paths, file_names\n",
    "kmz_file_paths, file_names = webscraping_kmz(base_directory)\n",
    "print(kmz_file_paths)\n",
    "print(file_names)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "KMZ file C:\\Users\\CrudeIntern\\OneDrive - Hengli Petrochemical International Pte Ltd\\Market Analysis\\Current Projects\\Hurricane\\wp2124.kmz has been extracted to C:\\Users\\CrudeIntern\\OneDrive - Hengli Petrochemical International Pte Ltd\\Market Analysis\\Current Projects\\Hurricane\\wp2124\n",
      "C:\\Users\\CrudeIntern\\OneDrive - Hengli Petrochemical International Pte Ltd\\Market Analysis\\Current Projects\\Hurricane\\wp2124.kml\n",
      "Error moving KML file: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\CrudeIntern\\\\OneDrive - Hengli Petrochemical International Pte Ltd\\\\Market Analysis\\\\Current Projects\\\\Hurricane\\\\wp2124\\\\doc.kml' -> 'C:\\\\Users\\\\CrudeIntern\\\\OneDrive - Hengli Petrochemical International Pte Ltd\\\\Market Analysis\\\\Current Projects\\\\Hurricane\\\\wp2124.kml'\n",
      "Folder C:\\Users\\CrudeIntern\\OneDrive - Hengli Petrochemical International Pte Ltd\\Market Analysis\\Current Projects\\Hurricane\\wp2124 has been deleted.\n",
      "KMZ file C:\\Users\\CrudeIntern\\OneDrive - Hengli Petrochemical International Pte Ltd\\Market Analysis\\Current Projects\\Hurricane\\wp2124.kmz has been deleted.\n",
      "KMZ file C:\\Users\\CrudeIntern\\OneDrive - Hengli Petrochemical International Pte Ltd\\Market Analysis\\Current Projects\\Hurricane\\ep9924.kmz has been extracted to C:\\Users\\CrudeIntern\\OneDrive - Hengli Petrochemical International Pte Ltd\\Market Analysis\\Current Projects\\Hurricane\\ep9924\n",
      "C:\\Users\\CrudeIntern\\OneDrive - Hengli Petrochemical International Pte Ltd\\Market Analysis\\Current Projects\\Hurricane\\ep9924.kml\n",
      "Error moving KML file: [WinError 183] Cannot create a file when that file already exists: 'C:\\\\Users\\\\CrudeIntern\\\\OneDrive - Hengli Petrochemical International Pte Ltd\\\\Market Analysis\\\\Current Projects\\\\Hurricane\\\\ep9924\\\\tcfa_doc.kml' -> 'C:\\\\Users\\\\CrudeIntern\\\\OneDrive - Hengli Petrochemical International Pte Ltd\\\\Market Analysis\\\\Current Projects\\\\Hurricane\\\\ep9924.kml'\n",
      "Folder C:\\Users\\CrudeIntern\\OneDrive - Hengli Petrochemical International Pte Ltd\\Market Analysis\\Current Projects\\Hurricane\\ep9924 has been deleted.\n",
      "KMZ file C:\\Users\\CrudeIntern\\OneDrive - Hengli Petrochemical International Pte Ltd\\Market Analysis\\Current Projects\\Hurricane\\ep9924.kmz has been deleted.\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def extract_kml(kmz_file_paths: list, file_names: list, base_directory: str) -> None:\n",
    "    kml_file_paths = []\n",
    "    for kmz_file_path, file_name in zip(kmz_file_paths, file_names):\n",
    "        output_directory = os.path.join(base_directory, file_name)\n",
    "        with zipfile.ZipFile(kmz_file_path, 'r') as zip_ref:\n",
    "            zip_ref.extractall(output_directory)\n",
    "        print(f\"KMZ file {kmz_file_path} has been extracted to {output_directory}\")\n",
    "        ld = os.listdir(output_directory)\n",
    "        kml_file = [file for file in ld if file.endswith('.kml')]\n",
    "        kml_file_path = os.path.join(output_directory, kml_file[0])\n",
    "        try:\n",
    "            new_kml_path = os.path.join(base_directory, f'{file_name}.kml')\n",
    "            print(new_kml_path)\n",
    "            os.rename(kml_file_path, new_kml_path)\n",
    "            print(f\"KML file has been moved and renamed to {new_kml_path}\")\n",
    "            kml_file_paths.append(new_kml_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Error moving KML file: {e}\")\n",
    "        try:\n",
    "            shutil.rmtree(output_directory)\n",
    "            print(f\"Folder {output_directory} has been deleted.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting folder {output_directory}: {e}\")\n",
    "        try:\n",
    "            os.remove(kmz_file_path)\n",
    "            print(f\"KMZ file {kmz_file_path} has been deleted.\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error deleting KMZ file {kmz_file_path}: {e}\")\n",
    "    return kml_file_paths\n",
    "kml_file_paths = extract_kml(kmz_file_paths, file_names, base_directory)\n",
    "print(kml_file_paths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wp2124', 'ep9924']\n",
      "No valid KML content was merged.\n"
     ]
    }
   ],
   "source": [
    "def parse_kml_file(kml_file):\n",
    "    \"\"\"\n",
    "    Parse a KML file and return its root element.\n",
    "    Args:\n",
    "        kml_file (str): The path to the KML file.\n",
    "    Returns:\n",
    "        root (Element): The root element of the parsed KML file.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        tree = etree.parse(kml_file)\n",
    "        return tree.getroot()\n",
    "    except etree.XMLSyntaxError as e:\n",
    "        print(f\"Error parsing file {kml_file}: {e}\")\n",
    "        return None\n",
    "\n",
    "def adjust_ids(element, id_suffix):\n",
    "    \"\"\"\n",
    "    Adjust IDs of elements to ensure uniqueness in the merged KML.\n",
    "    Args:\n",
    "        element (Element): The root element whose child IDs need adjustment.\n",
    "        id_suffix (int): A unique suffix to append to IDs.\n",
    "    \"\"\"\n",
    "    for elem in element.iter():\n",
    "        if 'id' in elem.attrib:\n",
    "            elem.attrib['id'] = f\"{elem.attrib['id']}_{id_suffix}\"\n",
    "\n",
    "def merge_kml_files(selected_files, output_file):\n",
    "    \"\"\"\n",
    "    Merge the selected KML files into a single KML file.\n",
    "    Args:\n",
    "        selected_files (list): List of KML files selected for merging.\n",
    "        output_file (str): The path for the output merged KML file.\n",
    "    \"\"\"\n",
    "    # Define the KML namespace\n",
    "    KML_NAMESPACE = \"http://www.opengis.net/kml/2.2\"\n",
    "    NSMAP = {None: KML_NAMESPACE}\n",
    "\n",
    "    # Create a root for the new KML file\n",
    "    merged_root = etree.Element('kml', nsmap=NSMAP)\n",
    "    merged_document = etree.SubElement(merged_root, 'Document')\n",
    "\n",
    "    # Keep track of unique IDs to avoid conflicts\n",
    "    id_counter = 0\n",
    "\n",
    "    for kml_file in selected_files:\n",
    "        root = parse_kml_file(kml_file)\n",
    "        if root is not None:\n",
    "            # Find the <Document> element inside each KML file\n",
    "            document = root.find(f'.//{{{KML_NAMESPACE}}}Document')\n",
    "            if document is not None:\n",
    "                # Adjust IDs to avoid conflicts\n",
    "                adjust_ids(document, id_counter)\n",
    "                id_counter += 1\n",
    "\n",
    "                # Append child elements of the <Document> to the merged document\n",
    "                for elem in document:\n",
    "                    merged_document.append(elem)\n",
    "            else:\n",
    "                # If <Document> is not found, check for <Folder> elements\n",
    "                folders = root.findall(f'.//{{{KML_NAMESPACE}}}Folder')\n",
    "                for folder in folders:\n",
    "                    adjust_ids(folder, id_counter)\n",
    "                    id_counter += 1\n",
    "                    merged_document.append(folder)\n",
    "        else:\n",
    "            print(f\"Failed to parse file {kml_file}.\")\n",
    "\n",
    "    if len(merged_document) > 0:\n",
    "        # Write the merged KML content into the output file\n",
    "        with open(output_file, 'wb') as f:\n",
    "            f.write(etree.tostring(merged_root, pretty_print=True, xml_declaration=True, encoding='UTF-8'))\n",
    "        print(f\"Merged KML file saved as: {output_file}\")\n",
    "    else:\n",
    "        print(\"No valid KML content was merged.\")\n",
    "print(file_names)\n",
    "output_combine_file = os.path.join(base_directory, 'hurricane_combined.kml')\n",
    "merge_kml_files(kml_file_paths, output_file=output_combine_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform the Geojson\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 424 (char 423)\n",
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 440 (char 439)\n",
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 457 (char 456)\n",
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 5224 (char 5223)\n",
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 5240 (char 5239)\n",
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 5257 (char 5256)\n",
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 10372 (char 10371)\n",
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 10388 (char 10387)\n",
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 10405 (char 10404)\n",
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 15536 (char 15535)\n",
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 15552 (char 15551)\n",
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 15569 (char 15568)\n",
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 24655 (char 24654)\n",
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 24671 (char 24670)\n",
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 24688 (char 24687)\n",
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 34347 (char 34346)\n",
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 34363 (char 34362)\n",
      "Error processing the GeoJSON file: Expecting ',' delimiter: line 1 column 34380 (char 34379)\n",
      "GeoJSON cleaned and saved successfully.\n"
     ]
    }
   ],
   "source": [
    "def kml_to_geojson(output_geojson_path: str, output_combine_file: str) -> None:\n",
    "    file = k2g.main.convert(kml_path_or_buffer=output_combine_file, feature_collection_name='hurricane_combined.geojson')\n",
    "    with open(output_geojson_path, 'w') as f:\n",
    "        f.write(str(file[0]))\n",
    "    with open(output_geojson_path, 'r') as f:\n",
    "        raw_geojson_content = f.read()\n",
    "    while True:\n",
    "        try:\n",
    "            raw_geojson_content = raw_geojson_content.replace(\"'\", '\"')\n",
    "            geojson_obj = json.loads(raw_geojson_content)\n",
    "            formatted_geojson_content = json.dumps(geojson_obj, indent=4)\n",
    "            with open(output_geojson_path, 'w') as f:\n",
    "                f.write(formatted_geojson_content)\n",
    "            print(\"GeoJSON cleaned and saved successfully.\")\n",
    "            break\n",
    "        except json.JSONDecodeError as e:\n",
    "            print(f\"Error processing the GeoJSON file: {e}\")\n",
    "            escape_index = e.colno - 2\n",
    "            raw_geojson_content = raw_geojson_content[:escape_index] + \"\\\\\" + raw_geojson_content[escape_index:]\n",
    "            for i, val in enumerate(raw_geojson_content[escape_index+2:]):\n",
    "                if val == '\"':\n",
    "                    raw_geojson_content = raw_geojson_content[:escape_index+i+2] + \"\\\\\" + raw_geojson_content[escape_index+i+2:] \n",
    "                    break\n",
    "\n",
    "output_geojson_path = os.path.join(base_directory, 'hurricane_combined.geojson')\n",
    "output_combine_file = os.path.join(base_directory, 'hurricane_combined.kml')\n",
    "kml_to_geojson(output_geojson_path, output_combine_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upload to github"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[WinError 2] The system cannot find the file specified",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[24], line 13\u001b[0m\n\u001b[0;32m     10\u001b[0m cmd \u001b[38;5;241m=\u001b[39m [bash_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m-c\u001b[39m\u001b[38;5;124m'\u001b[39m, script_path]\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# Execute the script\u001b[39;00m\n\u001b[1;32m---> 13\u001b[0m shellscript \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPopen(cmd, stdout\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, stderr\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mSTDOUT, stdin\u001b[38;5;241m=\u001b[39msubprocess\u001b[38;5;241m.\u001b[39mPIPE, text\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m     15\u001b[0m \u001b[38;5;66;03m# Read and print the output line by line\u001b[39;00m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m line \u001b[38;5;129;01min\u001b[39;00m shellscript\u001b[38;5;241m.\u001b[39mstdout:\n",
      "File \u001b[1;32mc:\\Users\\CrudeIntern\\anaconda3\\Lib\\subprocess.py:1026\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[1;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize, process_group)\u001b[0m\n\u001b[0;32m   1022\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[0;32m   1023\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[0;32m   1024\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m-> 1026\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_execute_child(args, executable, preexec_fn, close_fds,\n\u001b[0;32m   1027\u001b[0m                         pass_fds, cwd, env,\n\u001b[0;32m   1028\u001b[0m                         startupinfo, creationflags, shell,\n\u001b[0;32m   1029\u001b[0m                         p2cread, p2cwrite,\n\u001b[0;32m   1030\u001b[0m                         c2pread, c2pwrite,\n\u001b[0;32m   1031\u001b[0m                         errread, errwrite,\n\u001b[0;32m   1032\u001b[0m                         restore_signals,\n\u001b[0;32m   1033\u001b[0m                         gid, gids, uid, umask,\n\u001b[0;32m   1034\u001b[0m                         start_new_session, process_group)\n\u001b[0;32m   1035\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[0;32m   1036\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[0;32m   1037\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[1;32mc:\\Users\\CrudeIntern\\anaconda3\\Lib\\subprocess.py:1538\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[1;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, unused_restore_signals, unused_gid, unused_gids, unused_uid, unused_umask, unused_start_new_session, unused_process_group)\u001b[0m\n\u001b[0;32m   1536\u001b[0m \u001b[38;5;66;03m# Start the process\u001b[39;00m\n\u001b[0;32m   1537\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1538\u001b[0m     hp, ht, pid, tid \u001b[38;5;241m=\u001b[39m _winapi\u001b[38;5;241m.\u001b[39mCreateProcess(executable, args,\n\u001b[0;32m   1539\u001b[0m                              \u001b[38;5;66;03m# no special security\u001b[39;00m\n\u001b[0;32m   1540\u001b[0m                              \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   1541\u001b[0m                              \u001b[38;5;28mint\u001b[39m(\u001b[38;5;129;01mnot\u001b[39;00m close_fds),\n\u001b[0;32m   1542\u001b[0m                              creationflags,\n\u001b[0;32m   1543\u001b[0m                              env,\n\u001b[0;32m   1544\u001b[0m                              cwd,\n\u001b[0;32m   1545\u001b[0m                              startupinfo)\n\u001b[0;32m   1546\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[0;32m   1547\u001b[0m     \u001b[38;5;66;03m# Child is launched. Close the parent's copy of those pipe\u001b[39;00m\n\u001b[0;32m   1548\u001b[0m     \u001b[38;5;66;03m# handles that only the child should have open.  You need\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1551\u001b[0m     \u001b[38;5;66;03m# pipe will not close when the child process exits and the\u001b[39;00m\n\u001b[0;32m   1552\u001b[0m     \u001b[38;5;66;03m# ReadFile will hang.\u001b[39;00m\n\u001b[0;32m   1553\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_pipe_fds(p2cread, p2cwrite,\n\u001b[0;32m   1554\u001b[0m                          c2pread, c2pwrite,\n\u001b[0;32m   1555\u001b[0m                          errread, errwrite)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [WinError 2] The system cannot find the file specified"
     ]
    }
   ],
   "source": [
    "import subprocess\n",
    "\n",
    "# Path to Git Bash executable\n",
    "bash_path = r\"C:\\Windows\\System32\\bash.exe\"  # Update this path based on where Git Bash is installed\n",
    "\n",
    "# Path to your shell script (.sh file)\n",
    "script_path = r\"C:/Users/CrudeIntern/OneDrive - Hengli Petrochemical International Pte Ltd/Market Analysis/Current Projects/Hurricane/auto_upload.sh\"\n",
    "\n",
    "# Prepare the command to run the script using Git Bash\n",
    "cmd = [bash_path, '-c', script_path]\n",
    "\n",
    "# Execute the script\n",
    "shellscript = subprocess.Popen(cmd, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, stdin=subprocess.PIPE, text=True)\n",
    "\n",
    "# Read and print the output line by line\n",
    "for line in shellscript.stdout:\n",
    "    print(line.strip())\n",
    "\n",
    "# Wait for the process to complete and get the return code\n",
    "returncode = shellscript.wait()\n",
    "print(f\"Process ended with the return code of {returncode}.\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
